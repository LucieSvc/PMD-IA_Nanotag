import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import os
import cv2
import keras
import import_ipynb
import random 
import math
from tensorflow.keras.losses import MeanSquaredError
from tensorflow.keras import layers, models, Input, Model
from tensorflow.keras.layers import Flatten, Dense, GlobalAveragePooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras import backend as K
from PIL import Image
from sklearn.utils import shuffle
from utils_notebook import redimensionner_images,afficher_images_reconstruites, charger_images_sans_labels, charger_les_donnees, data_augmentation
from sklearn.model_selection import train_test_split  # Pour la division train/validation
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda, BatchNormalization
from tensorflow.keras.applications import VGG16
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA


# 1. Configuration des chemins et paramètres
test_dir = r"C:\Users\sauvi\Desktop\Notebooks Python\notebooks\PMD\donnees\test"


og_dir = r"D:\Lucie\Insa Toulouse\4A\Projet\petit"
train_dir = r"D:\Lucie\Insa Toulouse\4A\Projet\petit_modifiees"

size_image_x=120
size_image_y=120
input_shape = (size_image_x, size_image_y, 1)


###### Chargement des données ######                            -------------------------------------> A refaire !!


#####################################
###### Visualisation images originales et modifiées ######      -------------------------------------> Utile ? ou à adapter ?

def afficher_donnees_avec_labels2(pairs1, pairs2, n_paires):
    fig, axes = plt.subplots(n_paires, 2, figsize=(8, 2 * n_paires))
    
    for i in range(n_paires):
        image_1 = pairs1[i]  # Image originale
        image_2 = pairs2[i]  # Image modifiée
        label = labels_pairs[i]  # Label de la paire (1 = similaire, 0 = différent)
        
        # Affichage des images
        axes[i, 0].imshow(image_1)  
        axes[i, 0].axis("off")
        axes[i, 0].set_title("Image originale")

        axes[i, 1].imshow(image_2)  
        axes[i, 1].axis("off")
        axes[i, 1].set_title("Image modifiée ")
    print(image_1.shape)
    print(image_2.shape)
    plt.tight_layout()
    plt.show()

afficher_donnees_avec_labels2(train_images_originales, train_images_modifiees, n_paires=5)


###### Autoencodeur ######
# Définir l'architecture de l'autoencodeur
inputs = layers.Input(shape=(size_image_y, size_image_x, 1))  # Entrée avec les bonnes dimensions

# Charger le modèle VGG16 pour la perte perceptuelle
vgg = VGG16(include_top=False, weights='imagenet', input_shape=(size_image_y, size_image_x, 3))
vgg.trainable = False

"""
# Fonction pour calculer la perte perceptuelle
def perceptual_loss(y_true, y_pred):
    y_true_resized = tf.image.resize(y_true, (size_image_y, size_image_x))
    y_pred_resized = tf.image.resize(y_pred, (size_image_y, size_image_x))
    
    y_true_resized = tf.reduce_mean(y_true_resized, axis=-1, keepdims=True)
    y_pred_resized = tf.reduce_mean(y_pred_resized, axis=-1, keepdims=True)
    # Convertir les images en RGB (si elles sont en niveaux de gris)
    y_true_3c = tf.image.grayscale_to_rgb(y_true_resized)
    y_pred_3c = tf.image.grayscale_to_rgb(y_pred_resized)
    
    # Passer les images dans le modèle VGG16 pour obtenir les caractéristiques
    y_true_features = vgg(y_true_3c)
    y_pred_features = vgg(y_pred_3c)
    
    # Retourner la différence entre les caractéristiques
    return tf.reduce_mean(tf.square(y_true_features - y_pred_features))

# Combiner perceptual_loss et MSE
def hybrid_loss(y_true, y_pred):
    perceptual = perceptual_loss(y_true, y_pred)
    mse = tf.reduce_mean(tf.square(y_true - y_pred))
    return perceptual + mse

# 5. Perte contrastive
def contrastive_loss(y_true, y_pred, margin=1):
    return K.mean(
        y_true * K.square(y_pred) +
        (1 - y_true) * K.square(K.maximum(margin - y_pred, 0))
    )
"""
latent_dim = 10

# Encoder
inputs = keras.Input(shape=(size_image_y, size_image_x, 1))  # Entrée avec les bonnes dimensions
x = layers.Conv2D(8, (3,3), activation='relu', padding='same')(inputs)
#layers.BatchNormalization(),
x = layers.MaxPooling2D((2,2), padding='same')(x)
#x = layers.Dropout(0.2)(x)  # Ajout de Dropout pour éviter le surapprentissage
x = layers.Conv2D(16, (3,3), activation='relu', padding='same')(x)
#layers.BatchNormalization(),
x = layers.MaxPooling2D((2,2), padding='same')(x)
#x = layers.Dropout(0.2)(x)
x = layers.Conv2D(32, (3,3), activation='relu', padding='same')(x)
#layers.BatchNormalization(),
x = layers.MaxPooling2D((2,2), padding='same')(x)
z = layers.Dropout(0.5)(x)
"""
x = layers.Conv2D(256, (3,3), activation='relu', padding='same')(x)
#layers.BatchNormalization(),
x = layers.MaxPooling2D((2,2), padding='same')(x)
x = layers.Dropout(0.5)(x)
"""
"""
x = layers.Flatten()(x)
x = layers.Dense(16, activation = "relu")(x)
z = layers.Dense(latent_dim)(x)
"""
encoder = keras.Model(inputs, z, name ="encoder")
encoder.summary()

#bottleneck
#x = layers.Conv2D(256, (3,3), activation='relu', padding='same')(x)
#x = layers.Conv2D(256, (3,3), activation='relu', padding='same')(x)
"""
# Decoder
decod = keras.Input(shape=(latent_dim,))  # Entrée avec les bonnes dimensions
x = layers.Dense(32 * 60 * 128, activation = "relu")(decod)
x = layers.Reshape((32, 60, 128))(x)
"""
decod=keras.Input(shape=(16, 16, 32))
"""
x = layers.Conv2DTranspose(256, (3,3), activation='relu', padding='same')(x)
x = layers.UpSampling2D((2,2))(x)
#layers.BatchNormalization(),

"""
x = layers.Conv2DTranspose(32, (3,3), activation='relu', padding='same')(decod)
#layers.BatchNormalization(),
x = layers.UpSampling2D((2,2))(x)
x = layers.Conv2DTranspose(16, (3,3), activation='relu', padding='same')(x)
#layers.BatchNormalization(),
x = layers.UpSampling2D((2,2))(x)
x = layers.Conv2DTranspose(8, (3,3), activation='relu', padding='same')(x)
x = layers.UpSampling2D((2,2))(x)
#layers.BatchNormalization(),
outputs = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x) # Sortie : Une image de même taille que l'entrée

decoder = keras.Model(decod, outputs, name = "decoder")
decoder.summary()

#inputs = keras.Input(shape=(size_image_y, size_image_x, 3))

latents = encoder(inputs)
outputs = decoder(latents)

ae = keras.Model(inputs, outputs, name = "ae")
ae.summary

# Compiler le modèle
#ae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.05), loss='mse', metrics=['accuracy'])
ae.compile(optimizer='adam', loss='mse', metrics=['accuracy'])

early_stopping = EarlyStopping(monitor='val_loss', patience=0.1, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=0.1, min_lr=0.1)

#train the model
callbacks = [keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=0.1, min_lr=0.1),
             keras.callbacks.TensorBoard(histogram_freq=1), keras.callbacks.EarlyStopping(monitor='val_loss', patience=0.1, restore_best_weights=True)
]

print(f"✅ Train modifiées: {train_images_modifiees.shape}, Train originales: {train_images_originales.shape}")

# Entraîner le modèle sur les paires d'images
ae.fit(
    train_images_modifiees, train_images_originales,  # Entrée modifiée et sortie originale
    epochs=10,
    batch_size=16,
    verbose = 1,
    validation_split=0.8,  # Vous pouvez aussi ajouter une validation
    #validation_data = (train_images_modifiees, train_images_originales),
    callbacks = callbacks
)

ae.save("ae_model.keras")

#######################################
###### Visualisation résultat autoencodeur ######
def afficher_reconstruction_autoencodeur(train_dir, og_dir, size_image_x, size_image_y, autoencoder):
    # Charger une image modifiée et une image originale pour vérifier la lecture
    img_modifiee_path = os.path.join(train_dir, "classe1", os.listdir(os.path.join(train_dir, "classe1"))[0])  # Exemple
    img_originale_path = os.path.join(og_dir, "classe1", os.listdir(os.path.join(og_dir, "classe1"))[0])  # Exemple

    # Chargement des images
    img_modifiee = cv2.imread(img_modifiee_path)
    img_modifiee = convert_to_grayscale(img_modifiee)
    img_originale = cv2.imread(img_originale_path)
    img_originale = convert_to_grayscale(img_originale)

    if img_modifiee is None or img_originale is None:
        print("⚠️ Une des images n'a pas été chargée correctement.")
        return

    # Redimensionnement et normalisation des images
    img_modifiee_resized = cv2.resize(img_modifiee, (size_image_x, size_image_y)) / 255.0
    img_originale_resized = cv2.resize(img_originale, (size_image_x, size_image_y)) / 255.0
    print(f"✅ img_modifiee_resized: {img_modifiee_resized.shape}")
    print(f"✅ img_originale_resized: {img_originale_resized.shape}")

    # Reconstruction via l'autoencodeur
    img_reconstruite = autoencoder.predict(np.expand_dims(img_modifiee_resized, axis=0))[0]
    
    # Recaler l'image reconstruite à la plage [0, 255] et convertir en uint8
    img_reconstruite_non_normalisee = np.clip(img_reconstruite * 255, 0, 255).astype(np.uint8)
    print(f"✅ img_reconstruite_non_normalisee: {img_reconstruite_non_normalisee.shape}")
    
    # Affichage des images
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))

    # Image modifiée (avant normalisation)
    axes[0].imshow(cv2.cvtColor(img_modifiee, cv2.COLOR_BGR2RGB))
    axes[0].set_title("Image modifiée")
    axes[0].axis("off")

    # Image originale (avant normalisation)
    axes[1].imshow(cv2.cvtColor(img_originale, cv2.COLOR_BGR2RGB))
    axes[1].set_title("Image originale")
    axes[1].axis("off")

    # Image reconstruite (non normalisée)
    axes[2].imshow(cv2.cvtColor(img_reconstruite_non_normalisee, cv2.COLOR_BGR2RGB))
    axes[2].set_title("Image reconstruite (non normalisée)")
    axes[2].axis("off")

    plt.show()

afficher_reconstruction_autoencodeur(train_dir, og_dir, size_image_x, size_image_y, ae)


#################################
###### Visualisation de l'encodeur ######
import matplotlib.pyplot as plt
import numpy as np
from sklearn.decomposition import PCA

# Sélectionner une image de test
idx = 0  # Indice d'une image test
image_test = np.expand_dims(train_images_modifiees[idx], axis=0)  # Ajouter batch dim

# Passer l'image dans l'encodeur pour récupérer la représentation latente
latent_representation = encoder.predict(image_test)

# Si la sortie est un tenseur 3D (H, W, C), afficher comme une carte de caractéristiques
if len(latent_representation.shape) == 4:
    latent_representation = np.squeeze(latent_representation)  # Supprimer la dimension batch
    num_filters = latent_representation.shape[-1]  # Nombre de cartes

    num_cols = 3  # Affichage avec 3 images par ligne (1 image originale + 2 features)
    num_rows = int(np.ceil((min(num_filters, 8) + 1) / num_cols))  # Nb de lignes

    fig, axes = plt.subplots(num_rows, num_cols, figsize=(num_cols * 5, num_rows * 5))

    # Afficher l'image originale en haut à gauche
    axes[0, 0].imshow(train_images_modifiees[idx])  
    axes[0, 0].axis("off")
    axes[0, 0].set_title("Image d'origine")

    # Affichage des cartes latentes
    for i in range(min(num_filters, 8)):  # Max 8 cartes pour éviter surcharge
        row, col = divmod(i + 1, num_cols)  # Décalage de 1 car image originale est en (0,0)
        axes[row, col].imshow(latent_representation[:, :, i], cmap="viridis")  
        axes[row, col].axis("off")
        axes[row, col].set_title(f"Feature {i}")

    # Supprimer les cases vides si besoin
    for i in range(min(num_filters, 8) + 1, num_rows * num_cols):
        fig.delaxes(axes[i // num_cols, i % num_cols])

    plt.tight_layout()
    plt.show()

# Si la sortie est un vecteur 1D, appliquer une réduction de dimension
elif len(latent_representation.shape) == 2:
    latent_2D = PCA(n_components=2).fit_transform(latent_representation)  
    plt.figure(figsize=(6, 6))
    plt.scatter(latent_2D[:, 0], latent_2D[:, 1], c="blue", alpha=0.7)
    plt.title("Représentation bottleneck (PCA)")
    plt.xlabel("Composante 1")
    plt.ylabel("Composante 2")
    plt.grid()
    plt.show()



################################
####### Chargement données de test ######     -------------------------------------> Mettre le chargement des donnnées de test dès le début !!!

# Dimensions pour le redimensionnement
resize_width, resize_height = 480, 256

def cropped_and_gray_image(img_path):
    """Charge une image, détecte un cercle, recadre autour et la convertit en niveaux de gris."""
    # Charger l'image
    image0 = cv2.imread(img_path)

    if image0 is None:
        print(f"Erreur : Impossible de charger {img_path}")
        return None  # Retourner None au lieu de 'continue'

    # Redimensionner l'image à 480x256 pour la détection du cercle
    image = cv2.resize(image0, (resize_width, resize_height))

    # Convertir en niveaux de gris
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Détecter les cercles avec HoughCircles
    circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, dp=1.2, minDist=300, param1=100, param2=10, minRadius=100, maxRadius=200)

    # Dimensions de l'image redimensionnée
    height, width = gray.shape
    center_x, center_y = width // 2, height // 2

    # Sélectionner le cercle le plus proche du centre, mais uniquement s'il est entièrement visible
    best_circle = None
    min_distance = float("inf")

    if circles is not None:
        for circle in circles[0, :]:
            x, y, r = circle

            # Vérifier que le cercle est entièrement contenu dans l'image
            if (x - r >= 0 and y - r >= 0 and x + r <= width and y + r <= height):
                distance_to_center = np.sqrt((x - center_x) ** 2 + (y - center_y) ** 2)
                if distance_to_center < min_distance:
                    min_distance = distance_to_center
                    best_circle = circle
    
    # Si un cercle a été détecté et validé
    if best_circle is not None:
        x, y, r = best_circle  # Coordonnées du cercle sur l'image redimensionnée

        # Mise à l'échelle des coordonnées et du rayon
        scale_x = image0.shape[1] / resize_width
        scale_y = image0.shape[0] / resize_height
        x = int(x * scale_x)
        y = int(y * scale_y)
        r = int(r * min(scale_x, scale_y))  # Adapter le rayon

        # Définir la taille du carré basé sur le diamètre
        side = 2 * r  

        # Calculer les nouvelles coordonnées pour assurer un carré
        x1, y1 = x - r, y - r
        x2, y2 = x + r, y + r

        # Vérifier que les coordonnées restent dans les limites de l'image
        x1, y1 = max(0, x1), max(0, y1)
        x2, y2 = min(image0.shape[1], x2), min(image0.shape[0], y2)

        # Recadrer l'image sur l'image originale
        cropped_image = image0[y1:y2, x1:x2]

        # Convertir en noir et blanc
        cropped_gray = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2GRAY)
        return cropped_gray  # Retourner l'image recadrée et en niveaux de gris
    else : 
        print(f"Aucun cercle trouvé pour: {img_path}")
        return None

def load_and_preprocess_test_images(load_dir, size_image_x, size_image_y):
    """Charge, recadre et prétraite les images de test en niveaux de gris"""
    test_images = []
    valid_file_names = []  # Liste pour stocker les fichiers valides
    test_image_files = [f for f in os.listdir(load_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

    for file in test_image_files:
        img_path = os.path.join(load_dir, file)
        try:
            img = cropped_and_gray_image(img_path)  # Récupérer l'image recadrée
            
            if img is not None:  # Si le recadrage a réussi
                img_resized = Image.fromarray(img).resize((size_image_x, size_image_y))
                img_array = np.array(img_resized) / 255.0  # Normalisation [0,1]
                test_images.append(img_array)
                valid_file_names.append(file)  # Ajouter uniquement si l'image est valide
            
        except Exception as e:
            print(f"❌ Erreur avec l'image {file}: {e}")

    if len(test_images) == 0:
        raise ValueError("❌ Aucune image de test chargée. Vérifiez le dossier des images de test.")

    return np.array(test_images), valid_file_names  # Retourne les noms filtrés


def load_and_preprocess_original_images(base_dir, size_image_x, size_image_y):
    """Charge toutes les images des sous-dossiers de base_dir et les prétraite."""
    images = []  # Liste pour stocker les images
    image_files = []  # Liste pour stocker les noms de fichiers
    base_files = [f for f in os.listdir(base_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]


    # Explorer chaque sous-dossier (classe)
    for class_name in os.listdir(base_dir):
        class_path = os.path.join(base_dir, class_name)

        # Vérifier que c'est bien un dossier avant de le parcourir
        if os.path.isdir(class_path):  
            for file_name in os.listdir(class_path):
                file_path = os.path.join(class_path, file_name)

                # Vérifier si c'est une image
                if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):
                    try:
                        # Charger l'image en niveaux de gris
                        img = Image.open(file_path).convert("L")  # "L" = grayscale
                        img_resized = img.resize((size_image_x, size_image_y))  # Redimensionner
                        img_array = np.array(img_resized) / 255.0  # Normalisation [0,1]

                        images.append(img_array)  # Ajouter à la liste
                        image_files.append(file_path)  # Stocker le chemin du fichier
                        
                    except Exception as e:
                        print(f"❌ Erreur avec l'image {file_name}: {e}")

    # Vérifier que des images ont bien été chargées
    if len(images) == 0:
        raise ValueError("Aucune image originale chargée. Vérifiez le dossier des images originales.")

    return np.array(images), image_files  # Conversion en numpy array après remplissage


# Afficher la liste des fichiers dans og_dir
print("Fichiers dans le dossier :", os.listdir(og_dir))

# Chargement des images
base_array, base_files = load_and_preprocess_original_images(og_dir, size_image_x, size_image_y)

print(f"{len(base_array)} images originales chargées.")
print("Fichiers chargés :", base_files)

# 9. Évaluation sur les images de test
test_images, test_image_files = load_and_preprocess_test_images(test_dir, size_image_x, size_image_y)
print("Test modèle siamois chargé !")

def show_images(images, file_names, title, cols=5):
    num_images = len(images)
    rows = math.ceil(num_images / cols)  # Calcul du nombre de lignes

    plt.figure(figsize=(cols * 3, rows * 3))  # Taille ajustée
    
    for i, (image, file_name) in enumerate(zip(images, file_names)):  
        plt.subplot(rows, cols, i + 1)
        plt.imshow(image, cmap="gray")  # Affichage en niveaux de gris
        plt.title(file_name, fontsize=8)  # Associer image et fichier
        plt.axis("off")

    plt.suptitle(title, fontsize=12)
    plt.tight_layout()
    plt.show()
    
# Afficher les images de test avec une grille plus lisible
show_images(test_images, test_image_files, "Images de test prétraitées")



##############################
####### Similarités MSE ######
name = []
for filename in os.listdir(test_dir):
    name.append(filename)

if len(base_array) == 0:
    raise ValueError("Aucune image originale chargée. Vérifiez le dossier des images originales.")
    
if len(test_images) == 0:
    raise ValueError("Aucune image de test chargée. Vérifiez le dossier des images de test.")
if len(test_images) > 0:  # Assurez-vous qu'il y a des images de test

    encoded_test_images = ae.predict(test_images)
   
    mse_loss = MeanSquaredError()
    similarities = []
    similar = 0
    
    for i, encoded_test in enumerate(encoded_test_images):
        for j, img_orig in enumerate(base_array):
            loss = mse_loss(img_orig, encoded_test)     ######
            similarity = 1 - loss.numpy()  # Inversion de la perte pour la similarité
            similarities.append(similarity)
            print(f"{name[i]} avec originale {j+1}: {'Modifiée' if similarity > 0.6 else 'Nouvelle'} (Sim: {similarity:.4f})")
            if similarity > similar :
                similar = similarity           
        print(f"Image {i+1}: {'Vrai' if similar > 0.6 else 'Faux'} (Sim: {similar:.4f})")
        
#################################
###### Test de validation des performances ######                  -------------------------------------> A Faire !! (ou ajuster les parties précédentes)
